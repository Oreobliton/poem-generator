Je veux faire un générateur de texte en me basant sur un modèle existant (surement RNN ou une optimisation de chaine de markov)
Pour ça je me pose beaucoup de questions.
D'un point de vu purement technique je sais au moins deux choses :
    - je veux le coder en Python
    - je veux traiter du texte en français
Déjà y'a la partie cleaning et accumulation de data. Plusieurs axes s'offrent à moi : 
    Les poèmes 
    Les chansons (parole.net) 
    Les horoscopes
C'est un choix un peu secondaire, la question principale est dans le choix du modèle pour l'instant.
Je suis en train de lire cet article (de blog) pour avoir des idées d'où aller :
https://towardsdatascience.com/exploring-wild-west-of-natural-language-generation-from-n-gram-and-rnns-to-seq2seq-2e816edd89c6

Le modèle n-gram est représentable avec mon approche actuelle (chaine de markov)
https://towardsdatascience.com/text-generation-using-n-gram-model-8d12d9802aa0

Je sais que je peux l'améliorer en utilisant le Q-Learning
Cet article explique bien le concept de q learning et les applications qu'il peut avoir :
https://blog.floydhub.com/an-introduction-to-q-learning-reinforcement-learning/
Je vois comment l'implémenter après il faut que le résultat soit vraiment meilleur que ce que 
je faisais avec mes n-grammes de base.
Il y'a d'autres sources dans la description : 
https://pathak22.github.io/noreward-rl/
https://ai.googleblog.com/2018/10/curiosity-and-procrastination-in.html
https://ai.googleblog.com/2019/02/learning-to-generalize-from-sparse-and.html



Je pense qu'on va faire 3 modèles : 
    Markov de base
    Markov + Q learning
    RNN
  
----->  On va les comparer avec le résultat de GPT2 ou 3
        On peut difficilement quantifier de manière automatique
        Donc il faudra comparer un peu à la main et tricher


J'essaye d'implémenter un modèle de q learning, je suis toujours dans le doute quant à quel poème choisir
et comment faire du "sur mesure" donc je me contente de mettre en place les infrastructure de code avant de
chercher des données.
Pour les qualifier mes résultats j'utilise ma base de donnée du rap français

J'aurai aimé concevoir une forme de Qlearning qui parte à l'envers.
On aurait pu générer les phrases les unes après les autres en partant d'un terminal.
Ceci aurait simplifié la séléction de rhymes.
Car cette même sélection laisse à désirer (non inclue dans l'algo mais dans un post traitement sur échantillon (j'ai peur que ça fausse l'expérience))
